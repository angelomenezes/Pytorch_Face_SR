{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.data_loader_RGB_resize import *\n",
    "from SRCNN_model import Net\n",
    "from utils.pytorch_ssim import *\n",
    "from utils.loss import *\n",
    "\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubPixelCNN parameters\n",
    "\n",
    "batch_size = 24\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "threads = 4\n",
    "upscale_factor = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_path_low = '../media/angelo/DATEN/Datasets/Experiment_Masters/300W-3D-low-res-56/train'\n",
    "#img_path_ref = '/media/angelo/DATEN/Datasets/Experiment_Masters/300W-3D-low-res-224/train'\n",
    "\n",
    "img_path_low = '/media/angelo/DATEN/Datasets/CelebA/LR_56/test/'\n",
    "img_path_ref = '/media/angelo/DATEN/Datasets/CelebA/HR/test/'\n",
    "\n",
    "train_set = DatasetSuperRes(img_path_low, img_path_ref)\n",
    "training_data_loader = DataLoader(dataset=train_set, num_workers=threads, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Building model\n"
     ]
    }
   ],
   "source": [
    "print('===> Building model')\n",
    "model = Net().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing loss\n",
    "\n",
    "feature_extraction_model = initialize_senet50_2048()\n",
    "face_loss = FacePerceptionLoss(feature_extraction_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = 'results/'\n",
    "out_model_path = 'models/'\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)    \n",
    "\n",
    "if not os.path.exists(out_model_path):\n",
    "    os.makedirs(out_model_path)   \n",
    "    \n",
    "results = {'avg_loss': [], 'psnr': [], 'ssim': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    epoch_loss = 0\n",
    "    epoch_total_loss = 0\n",
    "    model.train()\n",
    "    for iteration, batch in enumerate(training_data_loader, 1):\n",
    "        input_, target = batch[0].to(device), batch[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        upsampled_img = model(input_)\n",
    "        # MSE Loss for PSNR estimation\n",
    "        loss = criterion(upsampled_img, target)\n",
    "        epoch_loss += loss.item()\n",
    "        # Face Loss\n",
    "        total_loss = face_loss(upsampled_img, target)\n",
    "        epoch_total_loss += total_loss.item()\n",
    "        #loss.backward()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(training_data_loader),\n",
    "                                                           total_loss.item()))\n",
    "    \n",
    "    scheduler.step() # Decrease learning rate after 100 epochs to 10% of its value\n",
    "    \n",
    "    psnr_epoch = 10*log10(1/(epoch_loss / len(training_data_loader)))\n",
    "    ssim_epoch = ssim(upsampled_img, target).item()\n",
    "    #avg_loss_batch = epoch_loss/len(training_data_loader)\n",
    "    avg_loss_batch = epoch_total_loss/len(training_data_loader)\n",
    "    \n",
    "    results['psnr'].append(psnr_epoch)\n",
    "    results['ssim'].append(ssim_epoch)\n",
    "    results['avg_loss'].append(avg_loss_batch)\n",
    "    \n",
    "    print(\"===> Epoch {} Complete: Avg.Total Loss: {:.4f} / PSNR: {:.4f} / SSIM {:.4f}\".format(epoch, \n",
    "                                                                                          avg_loss_batch, \n",
    "                                                                                          psnr_epoch,\n",
    "                                                                                          ssim_epoch))\n",
    "    if epoch % (epochs // 5) == 0:\n",
    "    \n",
    "        data_frame = pd.DataFrame(\n",
    "                data={'Avg. Total Loss': results['avg_loss'], 'PSNR': results['psnr'], 'SSIM': results['ssim']},\n",
    "                index=range(1, epoch + 1))\n",
    "\n",
    "        data_frame.to_csv(out_path + 'SRCNN_Loss_x' + str(upscale_factor) + '_train_results.csv', index_label='Epoch')\n",
    "        \n",
    "        checkpoint(epoch)\n",
    "\n",
    "def checkpoint(epoch):\n",
    "    path = out_model_path + \"SRCNN_Loss_x{}_epoch_{}.pth\".format(upscale_factor, epoch)\n",
    "    torch.save(model, path)\n",
    "    print(\"Checkpoint saved to {}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[1](1/84): Loss: 22747.7246\n",
      "===> Epoch[1](2/84): Loss: 247056.2812\n",
      "===> Epoch[1](3/84): Loss: 13512.1543\n",
      "===> Epoch[1](4/84): Loss: 2982.3679\n",
      "===> Epoch[1](5/84): Loss: 18682.2715\n",
      "===> Epoch[1](6/84): Loss: 2627.6055\n",
      "===> Epoch[1](7/84): Loss: 2532.3657\n",
      "===> Epoch[1](8/84): Loss: 7137.5854\n",
      "===> Epoch[1](9/84): Loss: 8444.3867\n",
      "===> Epoch[1](10/84): Loss: 5293.2153\n",
      "===> Epoch[1](11/84): Loss: 2815.3018\n",
      "===> Epoch[1](12/84): Loss: 2737.7336\n",
      "===> Epoch[1](13/84): Loss: 6026.2012\n",
      "===> Epoch[1](14/84): Loss: 3373.8098\n",
      "===> Epoch[1](15/84): Loss: 550.5772\n",
      "===> Epoch[1](16/84): Loss: 1165.3961\n",
      "===> Epoch[1](17/84): Loss: 2953.0942\n",
      "===> Epoch[1](18/84): Loss: 3407.6226\n",
      "===> Epoch[1](19/84): Loss: 2911.1360\n",
      "===> Epoch[1](20/84): Loss: 2490.4568\n",
      "===> Epoch[1](21/84): Loss: 2015.0447\n",
      "===> Epoch[1](22/84): Loss: 1493.1608\n",
      "===> Epoch[1](23/84): Loss: 1139.5631\n",
      "===> Epoch[1](24/84): Loss: 461.5908\n",
      "===> Epoch[1](25/84): Loss: 741.5604\n",
      "===> Epoch[1](26/84): Loss: 1487.0364\n",
      "===> Epoch[1](27/84): Loss: 1649.1721\n",
      "===> Epoch[1](28/84): Loss: 1153.8096\n",
      "===> Epoch[1](29/84): Loss: 1025.2198\n",
      "===> Epoch[1](30/84): Loss: 938.4833\n",
      "===> Epoch[1](31/84): Loss: 727.1783\n",
      "===> Epoch[1](32/84): Loss: 505.3590\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect training\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
