{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super-resolve output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data\n",
    "\n",
    "#low_res_img_path = '/media/angelo/DATEN/Datasets/Experiment_Masters/300W-3D-low-res-28/test/AFW_37096733_1.jpg'\n",
    "low_res_img_path = '/media/angelo/DATEN/Datasets/Experiment_Masters/300W-3D-crap-112/test/AFW_37096733_1.jpg'\n",
    "\n",
    "original_img_path = '/media/angelo/DATEN/Datasets/Experiment_Masters/300W-3D-low-res-224/test/AFW_37096733_1.jpg'\n",
    "\n",
    "model_path = 'models/SRCNN_model_300LFW_x2_224.pth'\n",
    "#model_path = 'models/SubPixelCNN_model_300LFW_x4_112.pth'\n",
    "#model_path = 'models/SRGAN_Generator_model_300LFW_x4_112.pth'\n",
    "#model_path = 'models/EDSR_model_300LFW_x4_112.pth'\n",
    "#model_path = 'models/VDSR_model_300LFW_x4_112.pth'\n",
    "#model_path = 'models/FSRCNN_model_300LFW_x4_112.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Image Setting\n",
    "\n",
    "GPU_IN_USE = torch.cuda.is_available()\n",
    "img = Image.open(low_res_img_path).convert('YCbCr')\n",
    "y, cb, cr = img.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image setting\n",
    "\n",
    "device = torch.device('cuda' if GPU_IN_USE else 'cpu')\n",
    "model = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "model = model.to(device)\n",
    "data = (ToTensor()(y)).view(1, -1, y.size[1], y.size[0])\n",
    "data = data.to(device)\n",
    "\n",
    "if GPU_IN_USE:\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output and save image\n",
    "\n",
    "out = model(data)\n",
    "out = out.cpu()\n",
    "out_img_y = out.data[0].numpy()\n",
    "out_img_y *= 255.0\n",
    "out_img_y = out_img_y.clip(0, 255)\n",
    "out_img_y = Image.fromarray(np.uint8(out_img_y[0]), mode='L')\n",
    "\n",
    "out_img_cb = cb.resize(out_img_y.size, Image.BICUBIC)\n",
    "out_img_cr = cr.resize(out_img_y.size, Image.BICUBIC)\n",
    "out_img = Image.merge('YCbCr', [out_img_y, out_img_cb, out_img_cr]).convert('RGB')\n",
    "\n",
    "#out_img.save('result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR and SSIM BICUBIC: 10.850 and 0.441\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input images must have the same dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-309a6f61b71c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m print('PSNR and SSIM BICUBIC: %.3f and %.3f' %(psnr(np.array(bicubic_img), np.array(real_img)), \n\u001b[1;32m      9\u001b[0m                                                ssim(np.array(bicubic_img), np.array(real_img), multichannel=True)))\n\u001b[0;32m---> 10\u001b[0;31m print('PSNR and SSIM MODEL:   %.3f and %.3f' %(psnr(np.array(out_img), np.array(real_img)), \n\u001b[0m\u001b[1;32m     11\u001b[0m                                                ssim(np.array(out_img), np.array(real_img), multichannel=True)))\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Github/virtual_envs/image_app/lib/python3.6/site-packages/skimage/metrics/simple_metrics.py\u001b[0m in \u001b[0;36mpeak_signal_noise_ratio\u001b[0;34m(image_true, image_test, data_range)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \"\"\"\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mcheck_shape_equality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_range\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Github/virtual_envs/image_app/lib/python3.6/site-packages/skimage/_shared/utils.py\u001b[0m in \u001b[0;36mcheck_shape_equality\u001b[0;34m(im1, im2)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;34m\"\"\"Raise an error if the shape do not match.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input images must have the same dimensions.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input images must have the same dimensions."
     ]
    }
   ],
   "source": [
    "# Checking image quality\n",
    "\n",
    "real_img = Image.open(original_img_path)\n",
    "bicubic_img = img.resize((224,224),resample=Image.BICUBIC)\n",
    "\n",
    "# PSNR and SSIM - Bilinear Interpolation\n",
    "\n",
    "print('PSNR and SSIM BICUBIC: %.3f and %.3f' %(psnr(np.array(bicubic_img), np.array(real_img)), \n",
    "                                               ssim(np.array(bicubic_img), np.array(real_img), multichannel=True)))\n",
    "print('PSNR and SSIM MODEL:   %.3f and %.3f' %(psnr(np.array(out_img), np.array(real_img)), \n",
    "                                               ssim(np.array(out_img), np.array(real_img), multichannel=True)))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,4,1)\n",
    "plt.gca().set_title('Low Res')\n",
    "plt.imshow(img)\n",
    "plt.subplot(1,4,2)\n",
    "plt.gca().set_title('Bicubic')\n",
    "plt.imshow(bicubic_img)\n",
    "plt.subplot(1,4,3)\n",
    "plt.gca().set_title('Neural Net')\n",
    "plt.imshow(out_img)\n",
    "plt.subplot(1,4,4)\n",
    "plt.gca().set_title('Original')\n",
    "plt.imshow(real_img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
