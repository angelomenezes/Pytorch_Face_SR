{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import torch\n",
    "import glob as gb\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pandas as pd \n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "os.sys.path.append('../')\n",
    "os.sys.path.append('../models/')\n",
    "\n",
    "from utils.loss import cos_sim\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing upsampling via SR\n",
    "class SuperResolveDL:\n",
    "    def __init__(self, model, size, channel, resize=True):\n",
    "        self.model = model\n",
    "        self.size = size\n",
    "        self.channel = channel\n",
    "        self.resize = resize\n",
    "        \n",
    "    def __call__(self, path=''):\n",
    "        if self.channel == 1:\n",
    "            img = Image.open(path).convert('YCbCr').resize((self.size,self.size),resample=Image.BICUBIC)\n",
    "            upsample, cb, cr = img.split()\n",
    "            if not self.resize:\n",
    "                upsample, _, _ = Image.open(path).convert('YCbCr').resize((40,40),resample=Image.BICUBIC).split()\n",
    "        elif self.channel == 3:\n",
    "            if self.resize: \n",
    "                upsample = Image.open(path).convert('RGB').resize((self.size,self.size),resample=Image.BICUBIC)\n",
    "            else:\n",
    "                upsample = Image.open(path).convert('RGB')\n",
    "        else:\n",
    "            raise Exception('Channel option not listed')\n",
    "        \n",
    "        data = (transforms.ToTensor()(upsample)).view(1, self.channel, upsample.size[1], upsample.size[0])\n",
    "        data = data.to(device)\n",
    "        out = self.model(data)\n",
    "        out = out.cpu()\n",
    "        out_img = out.data[0].numpy()\n",
    "        out_img *= 255.0\n",
    "        out_img = out_img.clip(0, 255)\n",
    "                \n",
    "        if self.channel == 1:\n",
    "            out_img = Image.fromarray(np.uint8(out_img[0]), mode='L')\n",
    "            out_img = Image.merge('YCbCr', [out_img, cb, cr]).convert('RGB')\n",
    "            #out_img = out_img.resize((160,160), Image.BICUBIC)\n",
    "        if self.channel == 3:\n",
    "            out_img = out_img.transpose((1,2,0))\n",
    "            out_img = Image.fromarray(np.uint8(out_img), mode='RGB')\n",
    "            out_img = out_img.resize((160,160), Image.BICUBIC)\n",
    "\n",
    "        return out_img\n",
    "    \n",
    "    \n",
    "# Testing upsampling via Bicubic\n",
    "\n",
    "def load_image(path='', size=160, resize=True): # Bicubic\n",
    "    img = Image.open(path)\n",
    "    if resize:\n",
    "        img = img.resize((size,size), resample=Image.BICUBIC)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SR Model Initialization\n",
    "\n",
    "GPU_IN_USE = torch.cuda.is_available()\n",
    "\n",
    "if GPU_IN_USE:\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "device = torch.device('cuda' if GPU_IN_USE else 'cpu')\n",
    "#model_path = '../checkpoints/SRCNN_coord_x4_epoch_50.pth'\n",
    "#model_path = '../checkpoints/SRGAN_x4_epoch_30.pth'\n",
    "#model_path = '../checkpoints/SRGAN_FaceLoss_x4_epoch_28.pth'\n",
    "#model_path = '../checkpoints/SubCNN_coord_x4_epoch_50.pth'\n",
    "#model_path = '../checkpoints/FSRCNN_coord_x4_epoch_50.pth'\n",
    "#model_path = '../checkpoints/FSRCNN_coord_Loss_x4_epoch_29.pth'\n",
    "model_path = '../checkpoints/SRGAN_coord_FaceLoss_x4_epoch_24.pth'\n",
    "\n",
    "\n",
    "model = torch.load(model_path, map_location=lambda storage, loc: storage.cuda(0))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "#resnet = InceptionResnetV1(pretrained='casia-webface').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_embedding(img_path):\n",
    "    img_as_tensor = transforms.ToTensor()(load_image(img_path))\n",
    "    img_emb = resnet(img_as_tensor.unsqueeze(0)).squeeze(0).detach().numpy()\n",
    "    return img_emb\n",
    "\n",
    "def return_batch_embedding(imgs_path):\n",
    "    img_array = [transforms.ToTensor()(load_image(path)) for path in imgs_path]\n",
    "    emb_array = [resnet(img.unsqueeze(0)).squeeze(0).detach().numpy() for img in img_array]\n",
    "    return np.array(emb_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_image = SuperResolveDL(model, size=56, channel=3, resize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________\n",
      "Classe3\n",
      "_____________________________________________________________\n",
      "For NoSizeMargin/\n",
      "Accuracy for Class Classe_1 was 0.8125\n",
      "Accuracy for Class Classe_2 was 0.8125\n",
      "Accuracy for Class Classe_3 was 0.8125\n",
      "Average accuracy was 81.25\n",
      "For 40/\n",
      "Accuracy for Class Classe_1 was 0.8125\n",
      "Accuracy for Class Classe_2 was 0.8125\n",
      "Accuracy for Class Classe_3 was 0.8125\n",
      "Average accuracy was 81.25\n",
      "For 40-1.3/\n",
      "Accuracy for Class Classe_1 was 0.8125\n",
      "Accuracy for Class Classe_2 was 0.8125\n",
      "Accuracy for Class Classe_3 was 0.7500\n",
      "Average accuracy was 79.17\n",
      "_____________________________________________________________\n",
      "Classe4\n",
      "_____________________________________________________________\n",
      "For NoSizeMargin/\n",
      "Accuracy for Class Classe_1 was 0.5714\n",
      "Accuracy for Class Classe_2 was 0.5000\n",
      "Accuracy for Class Classe_3 was 0.5385\n",
      "Average accuracy was 53.66\n",
      "For 40/\n",
      "Accuracy for Class Classe_1 was 0.5000\n",
      "Accuracy for Class Classe_2 was 0.4286\n",
      "Accuracy for Class Classe_3 was 0.2308\n",
      "Average accuracy was 38.64\n",
      "For 40-1.3/\n",
      "Accuracy for Class Classe_1 was 0.7857\n",
      "Accuracy for Class Classe_2 was 0.7143\n",
      "Accuracy for Class Classe_3 was 0.5385\n",
      "Average accuracy was 67.95\n",
      "_____________________________________________________________\n",
      "Classe5\n",
      "_____________________________________________________________\n",
      "For NoSizeMargin/\n",
      "Accuracy for Class Classe_1 was 0.9000\n",
      "Accuracy for Class Classe_2 was 0.8000\n",
      "Accuracy for Class Classe_3 was 0.9000\n",
      "Average accuracy was 86.67\n",
      "For 40/\n",
      "Accuracy for Class Classe_1 was 0.8000\n",
      "Accuracy for Class Classe_2 was 0.8000\n",
      "Accuracy for Class Classe_3 was 0.8000\n",
      "Average accuracy was 80.00\n",
      "For 40-1.3/\n",
      "Accuracy for Class Classe_1 was 0.7000\n",
      "Accuracy for Class Classe_2 was 0.6000\n",
      "Accuracy for Class Classe_3 was 0.8000\n",
      "Average accuracy was 70.00\n"
     ]
    }
   ],
   "source": [
    "# Experimentation\n",
    "\n",
    "name_of_classes = ['Classe3', 'Classe4', 'Classe5']\n",
    "\n",
    "folder_data_size = ['NoSizeMargin/', '40/', '40-1.3/']\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "for name in name_of_classes:\n",
    "    \n",
    "    print('_____________________________________________________________')\n",
    "    print(name)\n",
    "    print('_____________________________________________________________')\n",
    "    \n",
    "    img_path = '/media/angelo/DATEN/Datasets/Dados_TCC_Joao/Material TCC/' + name + '/Classe/faces_bd/'\n",
    "\n",
    "    for data_size in folder_data_size:\n",
    "        print('For ' + data_size)\n",
    "\n",
    "        gallery_path = gb.glob(img_path + 'gallery-' + data_size + '*.png')\n",
    "        gallery_names = [os.path.splitext(name)[0] for name in os.listdir(img_path + 'gallery-' + data_size)]\n",
    "\n",
    "        face_embeddings = return_batch_embedding(gallery_path)\n",
    "\n",
    "        probe_path = img_path + 'probe-' + data_size\n",
    "        class_folder = [folder for folder in os.listdir(probe_path) if os.path.isdir(os.path.join(probe_path, folder))] \n",
    "        average_accuracy = 0\n",
    "\n",
    "        for classe in class_folder:\n",
    "\n",
    "            accuracy = 0\n",
    "            class_probe_path = probe_path + classe + '/'\n",
    "            student_pool_list = os.listdir(class_probe_path)\n",
    "\n",
    "            for index, student in enumerate(student_pool_list):\n",
    "\n",
    "                student_emb = return_embedding(class_probe_path + student)\n",
    "\n",
    "                similarities = [cos_sim(student_emb, face_embeddings[i]) for i in range(len(face_embeddings))]\n",
    "\n",
    "                least_dis = np.argmin(np.array(similarities))\n",
    "\n",
    "                if student[:2] == gallery_names[least_dis][:2]:\n",
    "                    accuracy += 1\n",
    "\n",
    "                #plt.figure(figsize=(5,5))\n",
    "                #plt.subplot(1,2,1)\n",
    "                #plt.imshow(load_image(gallery_path[least_dis]))\n",
    "                #plt.subplot(1,2,2)\n",
    "                #plt.imshow(load_image(class_probe_path + student))\n",
    "\n",
    "            average_accuracy += accuracy/len(student_pool_list)\n",
    "\n",
    "            print('Accuracy for Class ' + classe + ' was {:.4f}'.format(accuracy/len(student_pool_list)))\n",
    "\n",
    "        print('Average accuracy was {:.2f}'.format(100*average_accuracy/3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
