{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import torch\n",
    "import glob as gb\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import torch.nn as nn\n",
    "\n",
    "model_path = '/home/angelo/Desktop/Github/Feature-Extractors/'\n",
    "os.sys.path.append(model_path)\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of models\n",
    "\n",
    "def initialize_senet50_2048():\n",
    "    import senet50_ft_pytorch.senet50_ft_dims_2048 as model\n",
    "    network = model.senet50_ft(weights_path=model_path + 'senet50_ft_pytorch/senet50_ft_dims_2048.pth')\n",
    "    network.eval()\n",
    "    return network\n",
    "\n",
    "def initialize_senet50_256():\n",
    "    import senet50_256_pytorch.senet50_256 as model\n",
    "    network = model.senet50_256(weights_path=model_path + 'senet50_256_pytorch/senet50_256.pth')\n",
    "    network.eval()\n",
    "    return network\n",
    "\n",
    "def initialize_senet50_128():\n",
    "    import senet50_128_pytorch.senet50_128 as model\n",
    "    network = model.senet50_128(weights_path=model_path + 'senet50_128_pytorch/senet50_128.pth')\n",
    "    network.eval()\n",
    "    return network\n",
    "\n",
    "def initialize_resnet50_128():\n",
    "    import resnet50_128_pytorch.resnet50_128 as model\n",
    "    network = model.resnet50_128(weights_path=model_path + 'resnet50_128_pytorch/resnet50_128.pth')\n",
    "    network.eval()\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "\n",
    "def cos_sim(a,b):\n",
    "    return 1 - dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "def euc_dis(a,b):\n",
    "    return norm(a-b)\n",
    "\n",
    "def load_image(path='', resize=False):\n",
    "    '''\n",
    "    VGGFace2 Data has mean = (131.0912, 103.8827, 91.4953)\n",
    "    and std = (1,1,1) with no scaling\n",
    "    '''\n",
    "    mean = (131.0912, 103.8827, 91.4953)\n",
    "    img = Image.open(path)\n",
    "    if resize:\n",
    "        img = img.resize((224,224), resample=PIL.Image.BICUBIC)\n",
    "    \n",
    "    img = np.array(img) - mean # Normalizing data before inference\n",
    "    return img\n",
    "    \n",
    "def load_data(path=''):\n",
    "    '''\n",
    "    VGGFace2 Data has mean = (131.0912, 103.8827, 91.4953)\n",
    "    and std = (1,1,1)\n",
    "    '''\n",
    "    mean = (131.0912, 103.8827, 91.4953)\n",
    "    shape = (224,224,3)\n",
    "    \n",
    "    short_size = 224.0\n",
    "    crop_size = shape\n",
    "    img = Image.open(path)\n",
    "    \n",
    "    im_shape = np.array(img.size)    # in the format of (width, height, *)\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    ratio = float(short_size) / np.min(im_shape)\n",
    "    img = img.resize(size=(int(np.ceil(im_shape[0] * ratio)),   # width\n",
    "                           int(np.ceil(im_shape[1] * ratio))),  # height\n",
    "                           resample=PIL.Image.BICUBIC)\n",
    "\n",
    "    x = np.array(img)  # image has been transposed into (height, width)\n",
    "    newshape = x.shape[:2]\n",
    "    h_start = (newshape[0] - crop_size[0])//2\n",
    "    w_start = (newshape[1] - crop_size[1])//2\n",
    "    x = x[h_start:h_start+crop_size[0], w_start:w_start+crop_size[1]]\n",
    "    x = x - mean\n",
    "    return x\n",
    "\n",
    "def chunks(l, n):\n",
    "    # For item i in a range that is a length of l,\n",
    "    for i in range(0, len(l), n):\n",
    "        # Create an index range for l of n items:\n",
    "        yield l[i:i+n]\n",
    "\n",
    "def image_encoding(model, facepaths, batch_size):\n",
    "    print('==> compute image-level feature encoding.')\n",
    "    num_faces = len(facepaths)\n",
    "    face_feats = np.empty((num_faces, 128))\n",
    "    imgpaths = facepaths\n",
    "    imgchunks = list(chunks(imgpaths, batch_size))\n",
    "\n",
    "    for c, imgs in enumerate(imgchunks):\n",
    "        im_array = np.array([load_data(path=i, shape=(224, 224, 3)) for i in imgs])\n",
    "        f = model(torch.Tensor(im_array.transpose(0, 3, 1, 2)))[1].detach().cpu().numpy()[:, :, 0, 0]\n",
    "        start = c * batch_size\n",
    "        end = min((c + 1) * batch_size, num_faces)\n",
    "        # This is different from the Keras model where the normalization has been done inside the model.\n",
    "        face_feats[start:end] = f / np.sqrt(np.sum(f ** 2, -1, keepdims=True))\n",
    "    \n",
    "    return face_feats\n",
    "\n",
    "def return_embedding(model, image, embedding_size=128):\n",
    "    face_feats = np.empty((1,embedding_size)) # Embedding size\n",
    "    im_array = np.array(image).reshape((1,3,224,224))\n",
    "    f = model(torch.Tensor(im_array))[1].detach().cpu().numpy()[:, :, 0, 0]\n",
    "    face_feats = f / np.sqrt(np.sum(f ** 2, -1, keepdims=True)) # Normalizing embedding\n",
    "    return face_feats.reshape(-1)\n",
    "\n",
    "def return_activations(model, image):\n",
    "    '''\n",
    "    Currently it only accepts SeNet50 activations.\n",
    "    '''\n",
    "    activations = list()\n",
    "    normalized_values = 0\n",
    "    im_array = np.array(image).reshape((1,3,224,224))\n",
    "    for i in range(2,7):\n",
    "        f = model(torch.Tensor(im_array))[i].detach().cpu().numpy()[:, :, 0, 0]\n",
    "        normalized_values = f / np.sqrt(np.sum(f ** 2, -1, keepdims=True))\n",
    "        activations.append(normalized_values.reshape(-1))\n",
    "    return np.array(activations)\n",
    "\n",
    "def face_perception_loss(model, img1, img2):\n",
    "    \n",
    "    activations_img1 = return_activations(model, img1)\n",
    "    activations_img2 = return_activations(model, img2)\n",
    "    loss = 0\n",
    "    \n",
    "    # L1 Error or L2 Error or Euclidean Distance\n",
    "    for layer in range(len(activations_img1)):\n",
    "        #loss += sum(np.abs(activations_img1[layer] - activations_img2[layer]))\n",
    "        loss += np.sum((activations_img1[layer] - activations_img2[layer])**2)\n",
    "        #loss += euc_dis(activations_img1[layer], activations_img2[layer])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity Loss\n",
      "0.01633930206298828\n",
      "Perceptual Loss\n",
      "0.6450169309973717\n"
     ]
    }
   ],
   "source": [
    "senet50 = initialize_senet50_2048()\n",
    "\n",
    "low_res_img_path = '/media/angelo/DATEN/Datasets/CelebA/LR_56/test/018520.jpg'\n",
    "original_img_path = '/media/angelo/DATEN/Datasets/CelebA/HR/test/018520.jpg'\n",
    "\n",
    "lr_img = load_data(low_res_img_path)\n",
    "hr_img = load_data(original_img_path)\n",
    "\n",
    "lr_emb = return_embedding(senet50, lr_img)\n",
    "hr_emb = return_embedding(senet50, hr_img)\n",
    "\n",
    "print('Identity Loss')\n",
    "print(cos_sim(lr_emb, hr_emb))\n",
    "      \n",
    "print('Perceptual Loss')\n",
    "print(face_perception_loss(senet50, lr_img, hr_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> compute image-level feature encoding.\n",
      "-> finish encoding 90 images.\n"
     ]
    }
   ],
   "source": [
    "img_path = '/media/angelo/DATEN/Datasets/ICB-RW/'\n",
    "\n",
    "gallery_path = gb.glob(img_path + 'gallery/*.jpg')\n",
    "gallery_names = np.array([int(os.path.splitext(name)[0][:-2]) for name in os.listdir(img_path + 'gallery/')])\n",
    "\n",
    "resnet50 = initialize_resnet50_128()\n",
    "senet50 = initialize_senet50_128()\n",
    "\n",
    "face_embeddings = image_encoding(resnet50, gallery_path, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentation\n",
    "probe_path = img_path + 'probe/'\n",
    "student_pool_list = [student for student in os.listdir(probe_path)]\n",
    "watch_list_images = []\n",
    "accuracy = 0\n",
    "\n",
    "for index, student in enumerate(student_pool_list):\n",
    "    print('For student ' + student)\n",
    "    probe_list_students = student_pool_list.copy()\n",
    "    watch_list_emb = []\n",
    "    \n",
    "    # First embeddings is always for the guilty student\n",
    "    guilty_student_image = random.choice(os.listdir(probe_path + student)) \n",
    "    guilty_student_image = load_data(probe_path + student + '/' + guilty_student_image)\n",
    "    watch_list_emb.append(return_embedding(senet50, guilty_student_image))\n",
    "    \n",
    "    probe_list_students.remove(student)\n",
    "    \n",
    "    watch_list_students = random.sample(probe_list_students, 4)\n",
    "    \n",
    "    for suspect in watch_list_students:\n",
    "        image = random.choice(os.listdir(probe_path + suspect))\n",
    "        watch_list_images.append(probe_path + suspect + '/' + image)\n",
    "        \n",
    "    for i, suspect in enumerate(watch_list_images):\n",
    "        image = load_data(suspect)\n",
    "        watch_list_emb.append(return_embedding(senet50, image))\n",
    "    \n",
    "    similarities = [np.abs(cos_sim(face_embeddings[index], watch_list_emb[i])) for i in range(5)]\n",
    "    \n",
    "    # If the least distance is the first element, let's sum 1\n",
    "    if np.argmin(np.array(similarities)) == 0:\n",
    "        accuracy += 1\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy/len(student_pool_list)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
